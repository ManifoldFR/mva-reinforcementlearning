{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJ_s4_nhhiyo"
   },
   "source": [
    "# Reinforcement Learning with Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.2.0 torchvision pyvirtualdisplay matplotlib seaborn pandas numpy pathlib gym\n",
    "!sudo apt-get install xvfb\n",
    "!git clone https://github.com/rlgammazero/mvarl_hands_on.git > /dev/null 2>&1\n",
    "!cd mvarl_hands_on && git pull origin master > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "from pprint import pprint\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pathlib import Path\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCsyvh4NhjUc"
   },
   "outputs": [],
   "source": [
    "# The following code is will be used to visualize the environments.\n",
    "\"\"\"\n",
    "def show_video(directory):\n",
    "    html = []\n",
    "    for mp4 in Path(directory).glob(\"*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append('''<video alt=\"{}\" autoplay \n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
    "\"\"\"\n",
    "\n",
    "def show_video(directory):\n",
    "    \"\"\"Using IPython.display.Video\"\"\"\n",
    "    all_vids = list(Path(directory).glob(\"*.mp4\"))\n",
    "    for mp4 in all_vids:\n",
    "        vid = ipythondisplay.Video(mp4)\n",
    "        ipythondisplay.display(vid)\n",
    "    \n",
    "display = Display(visible=0, size=(900, 400))\n",
    "display.start();\n",
    "\n",
    "def make_seed(seed):\n",
    "    np.random.seed(seed=seed)\n",
    "    torch.manual_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThnSNaSMhnXa"
   },
   "source": [
    "PyTorch is a Python package that provides two high-level features:\n",
    "- Tensor computation (like NumPy) with strong GPU acceleration\n",
    "- Deep neural networks built on a tape-based autograd system\n",
    "\n",
    "At a granular level, PyTorch is a library that consists of the following components:\n",
    "\n",
    "| Component | Description |\n",
    "| ---- | --- |\n",
    "| [**torch**](https://pytorch.org/docs/stable/torch.html) | a Tensor library like NumPy, with strong GPU support |\n",
    "| [**torch.autograd**](https://pytorch.org/docs/stable/autograd.html) | a tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |\n",
    "| [**torch.jit**](https://pytorch.org/docs/stable/jit.html) | a compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code  |\n",
    "| [**torch.nn**](https://pytorch.org/docs/stable/nn.html) | a neural networks library deeply integrated with autograd designed for maximum flexibility |\n",
    "| [**torch.multiprocessing**](https://pytorch.org/docs/stable/multiprocessing.html) | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |\n",
    "| [**torch.utils**](https://pytorch.org/docs/stable/data.html) | DataLoader and other utility functions for convenience |\n",
    "\n",
    "\n",
    "**Tutorials on PyTorch:** https://pytorch.org/tutorials/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlZQl9TjhuWY"
   },
   "source": [
    "## OpenAI gym\n",
    "We will consider environments provided by OpenAI gym\n",
    "This library provides a large number of environments to test RL algorithm.\n",
    "\n",
    "We will focus on the **CartPole-v1** environment in this lab but we encourage you to also test your code on:\n",
    "* **Acrobot-v1**\n",
    "* **MountainCar-v0**\n",
    "\n",
    "| Env Info          \t| CartPole-v1 \t| Acrobot-v1                \t| MountainCar-v0 \t|\n",
    "|-------------------\t|-------------\t|---------------------------\t|----------------\t|\n",
    "| **Observation Space** \t| Box(4)      \t| Box(6)                    \t| Box(2)         \t|\n",
    "| **Action Space**      \t| Discrete(2) \t| Discrete(3)               \t| Discrete(3)    \t|\n",
    "| **Rewards**           \t| 1 per step  \t| -1 if not terminal else 0 \t| -1 per step    \t|\n",
    "\n",
    "A gym environment is loaded with the command `env = gym.make(env_id)`. Once the environment is created, you need to reset it with `observation = env.reset()` and then you can interact with it using the method step: `observation, reward, done, info = env.step(action)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wfHvW9Hh4H3"
   },
   "outputs": [],
   "source": [
    "# We load CartPole-v1\n",
    "env = gym.make('CartPole-v1')\n",
    "# We wrap it in order to save our experiment on a file.\n",
    "env = Monitor(env, \"./gym-results\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-fFj5sDiA0C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"gym-results/openaigym.video.0.20110.video000000.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "env.close()\n",
    "show_video(\"./gym-results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sd2xLlapilZE"
   },
   "source": [
    "## REINFORCE\n",
    "\n",
    "**Q1: Implement the REINFORCE algorithm**\n",
    "\n",
    "The code is splitted in two parts:\n",
    "* The Model class defines the architecture of our neural network which takes as input the current state and returns the policy,\n",
    "* The Agent class is responsible for the training and evaluation procedure. You will need to code the method `optimize_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwsQ8NSPiCz7"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dim_observation, n_actions):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.n_actions = n_actions\n",
    "        self.dim_observation = dim_observation\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=self.dim_observation, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=self.n_actions),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        return self.net(state)\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        action = torch.multinomial(self.forward(state), 1)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrgtQMYbiwX7"
   },
   "source": [
    "Create the model based on the properties of the MDP you want to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6ieL_KJirq9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model we created correspond to:\n",
      "Model(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=2, bias=True)\n",
      "    (5): Softmax(dim=0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "env = gym.make(env_id)\n",
    "model = Model(env.observation_space.shape[0], env.action_space.n)\n",
    "print(f'The model we created correspond to:\\n{model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwrVF9kti1e-"
   },
   "source": [
    "We provide a base agent that you will need to extend in the next cell with your implementation of `optimize_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWvKO66ii1zh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "class BaseAgent:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = gym.make(config['env_id'])\n",
    "        make_seed(config['seed'])\n",
    "        self.env.seed(config['seed'])\n",
    "        self.model = Model(self.env.observation_space.shape[0],\n",
    "                           self.env.action_space.n)\n",
    "        self.gamma = config['gamma']\n",
    "        \n",
    "        # the optimizer used by PyTorch (Stochastic Gradient, Adagrad, Adam, etc.)\n",
    "        self.optimizer = torch.optim.Adam(self.model.net.parameters(), lr=config['learning_rate'])\n",
    "        self.monitor_env = Monitor(self.env, \"./gym-results\", force=True, \n",
    "                                   video_callable=lambda episode: True)\n",
    "    \n",
    "        self.current_ep = 0\n",
    "        self.rewards = []\n",
    "    \n",
    "    # Method to implement\n",
    "    def _compute_returns(self, rewards):\n",
    "        \"\"\"Returns the cumulative discounted rewards at each time step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rewards : array\n",
    "            The array of rewards of one episode\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "            The cumulative discounted rewards at each time step\n",
    "            \n",
    "        Example\n",
    "        -------\n",
    "        for rewards=[1, 2, 3] this method outputs [1 + 2 * gamma + 3 * gamma**2, 2 + 3 * gamma, 3] \n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # Method to implement\n",
    "    def optimize_model(self, n_trajectories):\n",
    "        \"\"\"Perform a gradient update using n_trajectories\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_trajectories : int\n",
    "            The number of trajectories used to approximate the expectation card(D) in the formula above\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "            The cumulative discounted rewards of each trajectory\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train(self, n_trajectories, n_update):\n",
    "        \"\"\"Training method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_trajectories : int\n",
    "            The number of trajectories used to approximate the expected gradient\n",
    "        n_update : int\n",
    "            The number of gradient updates\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        final_update = self.current_ep + n_update\n",
    "        rewards = self.rewards  # restart the reward record\n",
    "        for episode in range(self.current_ep, final_update):\n",
    "            rewards.append(self.optimize_model(n_trajectories))\n",
    "            print(f'Episode {episode + 1}/{final_update}: rewards ' \n",
    "                  +f'{round(rewards[-1].mean(), 2)} +/- {round(rewards[-1].std(), 2)}')\n",
    "            self.current_ep += 1\n",
    "        \n",
    "        # Plotting\n",
    "        r = pd.DataFrame((itertools.chain(*(itertools.product([i], rewards[i]) for i in range(len(rewards))))), columns=['Epoch', 'Reward'])\n",
    "        sns.lineplot(x=\"Epoch\", y=\"Reward\", data=r, ci='sd');\n",
    "        \n",
    "    def evaluate(self, render=False):\n",
    "        \"\"\"Evaluate the agent on a single trajectory            \n",
    "        \"\"\"\n",
    "        \n",
    "        ## Wrap in torch.no_grad to stop the tape recorder\n",
    "        ## and stop the RAM from blowing up\n",
    "        with torch.no_grad():\n",
    "            observation = self.monitor_env.reset()\n",
    "            observation = torch.from_numpy(observation).float()\n",
    "            reward_episode = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.model.select_action(observation)\n",
    "                observation, reward, done, info = self.monitor_env.step(int(action))\n",
    "                observation = torch.from_numpy(observation).float()\n",
    "                reward_episode = self.gamma * reward_episode + reward\n",
    "        self.monitor_env.close()\n",
    "        if render:\n",
    "            show_video(\"./gym-results\")\n",
    "        print(f'Reward: {reward_episode}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6mhw_A3i_8R"
   },
   "source": [
    "Finally you can implement your agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** The REINFORCE algorithm uses an unbiased estimate of the gradient of\n",
    "$$\n",
    "    J(\\pi_\\theta) = \\mathbb E_{\\tau\\sim \\mathbb P_\\theta}\\left[ R(\\tau) \\right]\n",
    "    = \\mathbb E_\\tau \\left[\n",
    "        \\sum_{t=0}^T \\gamma^t r_t\n",
    "    \\right]\n",
    "$$\n",
    "which has exact gradient\n",
    "$$\n",
    "    \\nabla_\\theta J(\\pi_\\theta) = \\mathbb E_{\\tau\\sim\\mathbb P_\\theta}\n",
    "    \\left[ R(\\tau)\\nabla_\\theta \\log \\pi_\\theta \\right] =\n",
    "    \\mathbb E_\\tau\\left[\n",
    "    \\left(\\sum_{t=0}^T \\gamma^t r_t\\right)\n",
    "    \\left(\\sum_{t=0}^T \\nabla_\\theta\\log \\pi_\\theta(s_t, a_t) \\right)\n",
    "    \\right]\n",
    "$$\n",
    "\n",
    "We introduce the pseudo-likelihood\n",
    "$$\n",
    "    L(\\theta) = \\frac{1}{M}\\sum_{i=1}^M\n",
    "    \\left(\\sum_{t=0}^T \\gamma^t r^i_t\\right)\n",
    "    \\left(\\sum_{t=0}^T \\log \\pi_\\theta(s^i_t, a^i_t) \\right) \\geq 0\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "    \\nabla_\\theta L(\\theta)\n",
    "$$\n",
    "is an unbiased estimate of the policy gradient $\\nabla_\\theta J(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbjP-7WHi9oc"
   },
   "outputs": [],
   "source": [
    "class REINFORCE(BaseAgent):\n",
    "    \n",
    "    def _compute_returns(self, rewards):\n",
    "        num_rew = len(rewards)\n",
    "        exponents = np.arange(num_rew)\n",
    "        gammas = np.power(self.gamma, exponents)\n",
    "        \n",
    "        return rewards.dot(gammas)\n",
    "    \n",
    "        \n",
    "    def optimize_model(self, n_trajectories):\n",
    "\n",
    "        env = self.env\n",
    "        reward_trajectories = np.empty(n_trajectories)\n",
    "        loss = 0.\n",
    "        \n",
    "        for i in range(n_trajectories):\n",
    "            traj_rewards = []  # rewards of the trajectory\n",
    "            traj_proba = 0.  # sum of log-probabilities of trajectory\n",
    "            \n",
    "            # Build trajectory\n",
    "            done = False\n",
    "            obs = env.reset()\n",
    "            obs = torch.from_numpy(obs).float()  # state s0\n",
    "            while not done:\n",
    "                action = self.model.select_action(obs)  # can be cast to int for action idx\n",
    "                # Get proba\n",
    "                prob = self.model(obs)[int(action)]\n",
    "                traj_proba += torch.log(prob)\n",
    "                \n",
    "                obs, reward, done, info = env.step(int(action))\n",
    "                \n",
    "                obs = torch.from_numpy(obs).float()\n",
    "                # Store the new reward\n",
    "                traj_rewards.append(reward)\n",
    "                \n",
    "                \n",
    "            traj_rewards = np.array(traj_rewards)  # NumPy array\n",
    "            \n",
    "            # Get total reward\n",
    "            total_reward = self._compute_returns(traj_rewards)  # NumPy array\n",
    "            reward_trajectories[i] = total_reward\n",
    "            \n",
    "            loss = loss + total_reward * traj_proba / n_trajectories  # accumulate the negative criterion\n",
    "        \n",
    "        env.close()  # important\n",
    "        \n",
    "        loss = -loss\n",
    "        \n",
    "        # The following lines take care of the gradient descent step for the variable loss\n",
    "        # that you need to compute.\n",
    "        print(\"Loss:\", loss.data.numpy())\n",
    "        \n",
    "        # Discard previous gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        # Compute the gradient \n",
    "        loss.backward()\n",
    "        # Do the gradient descent step\n",
    "        self.optimizer.step()\n",
    "        return reward_trajectories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZAo0K8VjCYj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config is:\n",
      "{'env_id': 'CartPole-v1', 'gamma': 1.0, 'learning_rate': 0.015, 'seed': 1235}\n"
     ]
    }
   ],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "learning_rate = 0.015\n",
    "gamma = 1.0  # every second counts the same\n",
    "seed = 1235\n",
    "\n",
    "config = {\n",
    "    'env_id': env_id,\n",
    "    'learning_rate': learning_rate,\n",
    "    'seed': seed,\n",
    "    'gamma': gamma\n",
    "}\n",
    "\n",
    "print(\"Current config is:\")\n",
    "pprint(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4Ag7E3qjJas"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 315.27423\n",
      "Episode 1/64: rewards 19.12 +/- 9.49\n",
      "Loss: 521.7329\n",
      "Episode 2/64: rewards 24.73 +/- 11.84\n",
      "Loss: 386.60022\n",
      "Episode 3/64: rewards 21.64 +/- 9.51\n",
      "Loss: 510.77228\n",
      "Episode 4/64: rewards 23.37 +/- 13.92\n",
      "Loss: 580.80133\n",
      "Episode 5/64: rewards 24.76 +/- 15.26\n",
      "Loss: 520.22894\n",
      "Episode 6/64: rewards 24.04 +/- 13.38\n",
      "Loss: 558.75836\n",
      "Episode 7/64: rewards 25.52 +/- 12.8\n",
      "Loss: 622.01666\n",
      "Episode 8/64: rewards 26.6 +/- 14.45\n",
      "Loss: 740.3721\n",
      "Episode 9/64: rewards 28.71 +/- 16.4\n",
      "Loss: 964.107\n",
      "Episode 10/64: rewards 32.19 +/- 19.85\n",
      "Loss: 1108.002\n",
      "Episode 11/64: rewards 32.95 +/- 23.93\n",
      "Loss: 1111.6567\n",
      "Episode 12/64: rewards 34.43 +/- 21.95\n",
      "Loss: 908.49414\n",
      "Episode 13/64: rewards 32.32 +/- 17.95\n",
      "Loss: 1045.6062\n",
      "Episode 14/64: rewards 35.4 +/- 18.0\n",
      "Loss: 1198.4823\n",
      "Episode 15/64: rewards 37.68 +/- 20.54\n",
      "Loss: 1046.5044\n",
      "Episode 16/64: rewards 35.75 +/- 18.17\n",
      "Loss: 1075.5834\n",
      "Episode 17/64: rewards 36.16 +/- 18.48\n",
      "Loss: 1223.8119\n",
      "Episode 18/64: rewards 38.48 +/- 20.45\n",
      "Loss: 1658.1143\n",
      "Episode 19/64: rewards 43.35 +/- 26.54\n",
      "Loss: 1474.7821\n",
      "Episode 20/64: rewards 42.77 +/- 22.29\n",
      "Loss: 1296.2067\n",
      "Episode 21/64: rewards 41.8 +/- 17.36\n",
      "Loss: 1466.902\n",
      "Episode 22/64: rewards 42.68 +/- 22.25\n",
      "Loss: 1585.6609\n",
      "Episode 23/64: rewards 45.37 +/- 22.09\n",
      "Loss: 2203.3499\n",
      "Episode 24/64: rewards 53.69 +/- 26.25\n",
      "Loss: 2504.766\n",
      "Episode 25/64: rewards 55.01 +/- 32.45\n",
      "Loss: 2836.0923\n",
      "Episode 26/64: rewards 61.56 +/- 29.44\n",
      "Loss: 3081.7432\n",
      "Episode 27/64: rewards 62.01 +/- 35.74\n",
      "Loss: 5043.2134\n",
      "Episode 28/64: rewards 79.73 +/- 47.23\n",
      "Loss: 3511.9473\n",
      "Episode 29/64: rewards 66.47 +/- 39.52\n",
      "Loss: 3380.1147\n",
      "Episode 30/64: rewards 69.31 +/- 32.61\n",
      "Loss: 4506.636\n",
      "Episode 31/64: rewards 79.59 +/- 40.41\n",
      "Loss: 6070.8706\n",
      "Episode 32/64: rewards 92.68 +/- 46.72\n",
      "Loss: 7249.139\n",
      "Episode 33/64: rewards 104.37 +/- 46.05\n",
      "Loss: 7793.4917\n",
      "Episode 34/64: rewards 112.09 +/- 38.79\n",
      "Loss: 7610.3677\n",
      "Episode 35/64: rewards 110.93 +/- 40.93\n",
      "Loss: 8999.748\n",
      "Episode 36/64: rewards 123.97 +/- 35.54\n",
      "Loss: 10140.078\n",
      "Episode 37/64: rewards 132.51 +/- 38.22\n",
      "Loss: 9560.032\n",
      "Episode 38/64: rewards 129.53 +/- 37.4\n",
      "Loss: 11307.697\n",
      "Episode 39/64: rewards 140.39 +/- 46.09\n",
      "Loss: 11550.833\n",
      "Episode 40/64: rewards 143.15 +/- 45.39\n",
      "Loss: 11215.28\n",
      "Episode 41/64: rewards 139.75 +/- 51.63\n",
      "Loss: 10564.065\n",
      "Episode 42/64: rewards 140.83 +/- 36.97\n",
      "Loss: 10986.353\n",
      "Episode 43/64: rewards 143.57 +/- 39.73\n",
      "Loss: 11400.541\n",
      "Episode 44/64: rewards 148.44 +/- 38.97\n",
      "Loss: 15552.787\n",
      "Episode 45/64: rewards 175.03 +/- 47.7\n",
      "Loss: 18317.928\n",
      "Episode 46/64: rewards 187.67 +/- 62.78\n",
      "Loss: 20243.656\n",
      "Episode 47/64: rewards 199.76 +/- 68.18\n",
      "Loss: 18813.236\n",
      "Episode 48/64: rewards 193.96 +/- 64.07\n",
      "Loss: 20091.488\n",
      "Episode 49/64: rewards 206.13 +/- 56.31\n",
      "Loss: 21228.467\n",
      "Episode 50/64: rewards 211.04 +/- 61.07\n",
      "Loss: 26279.984\n",
      "Episode 51/64: rewards 229.6 +/- 82.06\n",
      "Loss: 22702.516\n",
      "Episode 52/64: rewards 220.37 +/- 57.05\n",
      "Loss: 23517.572\n",
      "Episode 53/64: rewards 221.63 +/- 64.69\n",
      "Loss: 23319.107\n",
      "Episode 54/64: rewards 219.77 +/- 70.45\n",
      "Loss: 26258.854\n",
      "Episode 55/64: rewards 235.28 +/- 67.82\n",
      "Loss: 30437.758\n",
      "Episode 56/64: rewards 254.31 +/- 76.93\n",
      "Loss: 40093.61\n",
      "Episode 57/64: rewards 295.2 +/- 80.66\n",
      "Loss: 45095.59\n",
      "Episode 58/64: rewards 300.99 +/- 120.0\n",
      "Loss: 56874.44\n",
      "Episode 59/64: rewards 340.13 +/- 127.38\n",
      "Loss: 63817.367\n",
      "Episode 60/64: rewards 362.93 +/- 131.33\n",
      "Loss: 79435.46\n",
      "Episode 61/64: rewards 413.24 +/- 120.78\n",
      "Loss: 90507.73\n",
      "Episode 62/64: rewards 448.97 +/- 85.42\n",
      "Loss: 92207.65\n",
      "Episode 63/64: rewards 454.45 +/- 73.56\n",
      "Loss: 108267.02\n",
      "Episode 64/64: rewards 498.25 +/- 15.03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = REINFORCE(config)\n",
    "\n",
    "agent.train(n_trajectories=75, n_update=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3_dvBl8jUc3"
   },
   "source": [
    "Now, we evaluate the agent over multiple episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPyqbIiCjO_-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"gym-results/openaigym.video.1.24149.video000000.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "agent.evaluate(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "# Save the model\n",
    "datetag = datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "\n",
    "PATH = f\"saved_models/reinforce_{datetag}.pth\"\n",
    "PATH\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHM2_CRFkNoA"
   },
   "source": [
    "## Policy Evaluation as Supervised Learning\n",
    "\n",
    "**Q2: Implement batched gradient algorithm**\n",
    "\n",
    "Define network for value function (ValueNetwork) and policy (ActorNetwork)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ValueNetwork` is an estimate $v_\\nu$ (parameterized by $\\nu \\in \\mathcal V$) of the value function $V^{\\pi_\\theta}$ of the current policy model $\\pi_\\theta$ (parameterized by $\\theta\\in\\Theta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GKxKzs5khxM"
   },
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    r\"\"\"\n",
    "    Approximation of the value function V under the current policy.\n",
    "    \n",
    "    This is the 'critic'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self(x).detach().numpy()[0]\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    r\"\"\"\n",
    "    Policy model network for the agent.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, action_size):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.softmax(self.fc3(out), dim=-1)\n",
    "        return out\n",
    "    \n",
    "    def select_action(self, x):\n",
    "        return torch.multinomial(self(x), 1).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBpNVkaAKLQz"
   },
   "source": [
    "The following `EvalAgent` defines an **evaluation agent**: using the prescribed policy $\\pi$, it runs trajectories to fit an estimate of the value function $V^\\pi$ modelled as a neural network $\\hat{v}_\\nu(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQ4Wu5B5KIIO"
   },
   "outputs": [],
   "source": [
    "class EvalAgent:\n",
    "    \"\"\"\n",
    "    This agent runs the prescribed policy (but does not learn it)\n",
    "    \"\"\"\n",
    "    def __init__(self, config, policy):\n",
    "        self.config = config\n",
    "        self.env = gym.make(config['env_id'])\n",
    "        make_seed(config['seed'])\n",
    "        self.env.seed(config['seed'])\n",
    "        self.monitor_env = Monitor(self.env, \"./gym-results\",\n",
    "                                   force=True, video_callable=lambda episode: True)\n",
    "        self.gamma = config['gamma']\n",
    "        self.policy: ActorNetwork = policy\n",
    "\n",
    "        self.value_hidden = 16\n",
    "        # Our network\n",
    "        self.value_network: ValueNetwork = ValueNetwork(\n",
    "            self.env.observation_space.shape[0], self.value_hidden, 1)\n",
    "\n",
    "        # optimizer -- singular: only for the value network\n",
    "        self.value_network_optimizer = optim.RMSprop(\n",
    "            self.value_network.parameters(),\n",
    "            lr=config['value_network']['learning_rate'])\n",
    "    \n",
    "    def _compute_returns(self, rewards, dones, next_value):\n",
    "        \"\"\"Returns the cumulative discounted rewards at each time step.\n",
    "        We are going to fit the value_network on this.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        rewards : array\n",
    "            An array of shape (batch_size,) containing the rewards given by the env\n",
    "        dones : array\n",
    "            An array of shape (batch_size,) containing the done bool indicator given by the env\n",
    "        next_value : float\n",
    "            The (estimated) value of the next state given by the value network\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        returns : array\n",
    "            The estimate of the advantage -- or rather the returns\n",
    "        \"\"\"\n",
    "        returns_ = np.empty_like(rewards)\n",
    "        R = next_value\n",
    "        for i in range(1, len(rewards)+1):\n",
    "            retro_prop = 1-dones[-i]  # whether to use the following value\n",
    "            R = rewards[-i] + self.gamma * retro_prop * R\n",
    "            returns_[-i] = R\n",
    "        \n",
    "        \n",
    "        \n",
    "        return returns_\n",
    "    \n",
    "    \n",
    "    def optimize_model(self, observations, returns): #actions, returns, advantages): what ?\n",
    "        \"\"\"Perform a gradient update using provided transitions\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observations : array\n",
    "            The observations\n",
    "        returns : array\n",
    "            The returns from each state\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss_value: int  <--- what ??\n",
    "            The loss value\n",
    "        \"\"\"\n",
    "        # Cast our array buffers into tensors\n",
    "        returns = torch.from_numpy(returns[:, None]).float()  # shape (batch_size,1)\n",
    "        observations = torch.from_numpy(observations).float()\n",
    "        \n",
    "        \n",
    "        ## STEP ONE: FIT THE VALUE NETWORK TO THE RETURNS\n",
    "        network_values = self.value_network(observations)  # shape (batch_size,)\n",
    "        mse_values = F.mse_loss(network_values, returns)\n",
    "        #print(\"MSE values:\", mse_values.item())\n",
    "        \n",
    "        # rmk: graph of mse_values only depends on weights of value_network\n",
    "        mse_values.backward()  # backprop step\n",
    "        self.value_network_optimizer.step()  # optimizer step\n",
    "        self.value_network_optimizer.zero_grad()  # zero the gradients\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def training_batch(self, epochs, batch_size):\n",
    "        \"\"\"Train the model over multiple epochs, by batches.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs\n",
    "        batch_size : int\n",
    "            The size of a batch\n",
    "        \"\"\"\n",
    "        episode_count = 0\n",
    "        actions = np.empty((batch_size,), dtype=np.int)\n",
    "        dones   = np.empty((batch_size,), dtype=np.bool)\n",
    "        rewards = np.empty((batch_size,), dtype=np.float)\n",
    "        \n",
    "        ## shape (batch_size, *obs_dims) -- buffer for observations\n",
    "        observations = np.empty(\n",
    "            (batch_size,) + self.env.observation_space.shape,\n",
    "            dtype=np.float)\n",
    "        \n",
    "        env = self.env\n",
    "        \n",
    "        obs = env.reset()\n",
    "        mse_test = []\n",
    "\n",
    "        ## EPISODE = TRAJECTORY\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Collect the variables computed at the previous step\n",
    "            for i in range(batch_size):\n",
    "                observations[i] = obs  # just observed s_t\n",
    "                obs_ = torch.from_numpy(obs).float()  # tensor\n",
    "                action = self.policy.select_action(obs_)  # act on just observed, action a_t\n",
    "                actions[i] = int(action)\n",
    "                \n",
    "                obs, reward, done, _ = self.env.step(int(action))  # step with env\n",
    "                \n",
    "                dones[i] = done\n",
    "                rewards[i] = reward\n",
    "                \n",
    "                # check if the observation we just got was terminal\n",
    "                if dones[i]:\n",
    "                    obs = self.env.reset()\n",
    "\n",
    "            # If our episode didn't end on the last step we need to compute the value for the last state\n",
    "            if dones[-1]:\n",
    "                next_value = 0  # no value function adjustment\n",
    "            else:\n",
    "                obs_ = torch.from_numpy(obs).float()\n",
    "                next_value = self.value_network(obs_)\n",
    "            \n",
    "            # Update episode_count\n",
    "            episode_count += sum(dones)\n",
    "\n",
    "            # Compute returns over the batch\n",
    "            returns = self._compute_returns(rewards, dones, next_value)\n",
    "            \n",
    "            # Learning step !\n",
    "            self.optimize_model(observations, returns)\n",
    "            \n",
    "            obs = env.reset()\n",
    "            \n",
    "            # Run a test of the value fit, every 50 epochs\n",
    "            if (epoch > 0 and epoch % 25 == 0) or epoch == epochs - 1:\n",
    "                L = []\n",
    "                for _ in range(10):\n",
    "                    obs_states, y_mc = self.evaluate()\n",
    "                    obs_states_tensor = torch.from_numpy(obs_states).float()  # no-copy tensor\n",
    "                    y_hat = self.value_network(obs_states_tensor).detach().numpy()\n",
    "                    err = y_mc - y_hat\n",
    "                    mse = np.mean(err ** 2)\n",
    "                    L.append(mse.item())\n",
    "                mse_test.append(L)\n",
    "                print(f'Epoch {epoch}/{epochs}: Value MSE: {np.mean(mse)}')\n",
    "\n",
    "        env.close()\n",
    "        \n",
    "        # Plotting\n",
    "        r = pd.DataFrame((itertools.chain(*(itertools.product([i], mse_test[i]) for i in range(len(mse_test))))), columns=['Epoch', 'MSE'])\n",
    "        sns.lineplot(x=\"Epoch\", y=\"MSE\", data=r, ci='sd');\n",
    "\n",
    "        print(f'The training was done over a total of {episode_count} episodes')\n",
    "\n",
    "    def evaluate(self, render=False):\n",
    "        \"\"\"Returns the observations and the estimated V-function (using first visit Monte-Carlo)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        states : array\n",
    "            Observations\n",
    "        returns : array\n",
    "            The estimate value function of each state\n",
    "        \"\"\"\n",
    "        env = self.monitor_env if render else self.env\n",
    "        observation = env.reset()\n",
    "        states = [observation.copy()]\n",
    "        rewards= []\n",
    "        observation = torch.from_numpy(observation).float()\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        with torch.no_grad():  # avoid wrecking the RAM\n",
    "            while not done:\n",
    "                action = self.policy.select_action(observation)\n",
    "\n",
    "\n",
    "                observation, reward, done, info = env.step(int(action))\n",
    "                for i in range(steps):\n",
    "                    rewards[i] = rewards[i] + np.power(self.gamma, steps-i)*reward\n",
    "                rewards.append(reward)\n",
    "                if not done:\n",
    "                    states.append(observation.copy())\n",
    "                observation = torch.from_numpy(observation).float()\n",
    "                steps += 1\n",
    "\n",
    "        env.close()\n",
    "        if render:\n",
    "            show_video(\"./gym-results\")\n",
    "            print(f'Reward: {reward_episode}')\n",
    "        states = np.array(states).reshape(-1, self.env.observation_space.shape[0])\n",
    "        returns = np.array(rewards).reshape(-1,1)\n",
    "        return states, returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IY1VIUHLNKn3"
   },
   "source": [
    "Define configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fvc-7jXDNNkG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config_td is:\n",
      "{'env_id': 'CartPole-v1',\n",
      " 'gamma': 0.99,\n",
      " 'seed': 1,\n",
      " 'value_network': {'learning_rate': 0.0018, 'reference': './CartPole_value.pt'}}\n"
     ]
    }
   ],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "value_learning_rate = 0.0018\n",
    "gamma = 0.99\n",
    "seed = 1\n",
    "\n",
    "config_td = {\n",
    "    'env_id': env_id,\n",
    "    'gamma': gamma,\n",
    "    'seed': seed,\n",
    "    'value_network': {'learning_rate': value_learning_rate, 'reference': './CartPole_value.pt'}\n",
    "}\n",
    "\n",
    "print(\"Current config_td is:\")\n",
    "pprint(config_td)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2lRnaF3NPyy"
   },
   "source": [
    "We create the policy network: for now we will use a prescribed, pre-trained policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkbHK_lXNShg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi(state) =  [1]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(config_td['env_id'])\n",
    "\n",
    "## Define the policy network\n",
    "policy = ActorNetwork(env.observation_space.shape[0], 16, env.action_space.n)  # policy model network\n",
    "policy.load_state_dict(torch.load('./mvarl_hands_on/data/CartPole_actor.pt'))  # load pre-trained weights\n",
    "state = torch.from_numpy(env.reset()).float()  # initial state\n",
    "print(\"pi(state) = \", policy.select_action(state))\n",
    "# del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y51M4EgtNU7Z"
   },
   "source": [
    "Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PFvnYLnNGvX"
   },
   "outputs": [],
   "source": [
    "agent = EvalAgent(config=config_td, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PFvnYLnNGvX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "dones:   [False False False False False False False False False False False  True\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.36151283, 10.46617457,  9.5617925 ,  8.64827525,  7.72553056,\n",
       "        6.79346521,  5.85198506,  4.90099501,  3.940399  ,  2.9701    ,\n",
       "        1.99      ,  1.        ,  7.72553056,  6.79346521,  5.85198506,\n",
       "        4.90099501,  3.940399  ,  2.9701    ,  1.99      ,  1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For sanity\n",
    "def _test_compute_returns():\n",
    "    n = 20\n",
    "    rewards = np.ones(n)\n",
    "    dones = np.zeros(n, dtype=np.bool)\n",
    "    dones[11] = True\n",
    "    print(\"rewards:\", rewards)\n",
    "    print(\"dones:  \", dones)\n",
    "    \n",
    "    next_value = 0\n",
    "    res = agent._compute_returns(rewards, dones, next_value)\n",
    "    return res\n",
    "\n",
    "_test_compute_returns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PFvnYLnNGvX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/800: Value MSE: 6699.2783622987345\n",
      "Epoch 50/800: Value MSE: 5991.503593194566\n",
      "Epoch 75/800: Value MSE: 5000.36452257365\n",
      "Epoch 100/800: Value MSE: 3896.6062193060234\n",
      "Epoch 125/800: Value MSE: 2774.2764289402803\n",
      "Epoch 150/800: Value MSE: 1984.9105483982623\n",
      "Epoch 175/800: Value MSE: 1343.6016007314533\n",
      "Epoch 200/800: Value MSE: 867.686032616007\n",
      "Epoch 225/800: Value MSE: 774.4276227922157\n",
      "Epoch 250/800: Value MSE: 625.192739645155\n",
      "Epoch 275/800: Value MSE: 611.1459028769558\n",
      "Epoch 300/800: Value MSE: 678.7645192390694\n",
      "Epoch 325/800: Value MSE: 632.5247390937847\n",
      "Epoch 350/800: Value MSE: 685.1034250006016\n",
      "Epoch 375/800: Value MSE: 672.3947369860234\n",
      "Epoch 400/800: Value MSE: 581.2606737359262\n",
      "Epoch 425/800: Value MSE: 615.2470994797874\n",
      "Epoch 450/800: Value MSE: 670.8317830639302\n",
      "Epoch 475/800: Value MSE: 611.3586502816598\n",
      "Epoch 500/800: Value MSE: 1065.0124682544758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manifold/miniconda3/envs/torch/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/800: Value MSE: 610.211428698839\n",
      "Epoch 550/800: Value MSE: 614.0521261402993\n",
      "Epoch 575/800: Value MSE: 592.7664170474463\n",
      "Epoch 600/800: Value MSE: 586.63135467209\n",
      "Epoch 625/800: Value MSE: 619.1606849363673\n",
      "Epoch 650/800: Value MSE: 609.0073950952403\n",
      "Epoch 675/800: Value MSE: 590.8101960486318\n",
      "Epoch 700/800: Value MSE: 614.1035989062791\n",
      "Epoch 725/800: Value MSE: 596.674730274731\n",
      "Epoch 750/800: Value MSE: 601.3044319361793\n",
      "Epoch 775/800: Value MSE: 949.6450564352031\n",
      "Epoch 799/800: Value MSE: 613.743812340003\n",
      "The training was done over a total of 834 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 800\n",
    "batch_size = 512\n",
    "agent.training_batch(epochs=EPOCHS, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantage Actor Critic (A2C)\n",
    "**Q3: Implement the A2C method**\n",
    "\n",
    "As usual we provide a structure you can use as starting point.\n",
    "\n",
    "\n",
    "\n",
    "**Note:** try to reuse previous parts of previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4EmYpAsjhKh"
   },
   "outputs": [],
   "source": [
    "class A2CAgent:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = gym.make(config['env_id'])\n",
    "        make_seed(config['seed'])\n",
    "        self.env.seed(config['seed'])\n",
    "        self.monitor_env = Monitor(self.env, \"./gym-results\", force=True, video_callable=lambda episode: True)\n",
    "        self.gamma = config['gamma']\n",
    "        self.entropy = config['entropy']\n",
    "        \n",
    "        # Our two networks\n",
    "        self.value_network = ValueNetwork(self.env.observation_space.shape[0], 16, 1)\n",
    "        self.actor_network = ActorNetwork(self.env.observation_space.shape[0], 16, self.env.action_space.n)\n",
    "        \n",
    "        # Their optimizers\n",
    "        self.value_network_optimizer: optim.Optimizer = optim.RMSprop(\n",
    "            self.value_network.parameters(), lr=config['value_network']['learning_rate'])\n",
    "        self.actor_network_optimizer: optim.Optimizer = optim.RMSprop(\n",
    "            self.actor_network.parameters(), lr=config['actor_network']['learning_rate'])\n",
    "        \n",
    "    # Hint: use it during training_batch\n",
    "    def _returns_advantages(self, rewards, dones, values, next_value):\n",
    "        \"\"\"Returns the cumulative discounted rewards at each time step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rewards : array\n",
    "            An array of shape (batch_size,) containing the rewards given by the env\n",
    "        dones : array\n",
    "            An array of shape (batch_size,) containing the done bool indicator given by the env\n",
    "        values : array\n",
    "            An array of shape (batch_size,) containing the values given by the value network\n",
    "        next_value : float\n",
    "            The value of the next state given by the value network\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        returns : array\n",
    "            The cumulative discounted rewards\n",
    "        advantages : array\n",
    "            The advantages\n",
    "        \"\"\"\n",
    "        returns_ = np.empty_like(rewards)\n",
    "        \n",
    "        R = next_value\n",
    "        for i in range(1, len(rewards)+1):\n",
    "            retro_prop = 1-dones[-i]  # whether to use the following value\n",
    "            R = rewards[-i] + self.gamma * retro_prop * R\n",
    "            returns_[-i] = R\n",
    "        \n",
    "        \n",
    "        #advantages = rewards\n",
    "        #advantages[:-1] += (1-dones[:-1]) * self.gamma * values[1:] - values[:-1]\n",
    "        #advantages[-1] += (1-dones[-1]) * self.gamma * next_value - values[-1]\n",
    "        advantages = returns_ - values\n",
    "        return returns_, advantages\n",
    "\n",
    "    def training_batch(self, epochs, batch_size):\n",
    "        \"\"\"Perform a training by batch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs\n",
    "        batch_size : int\n",
    "            The size of a batch\n",
    "        \"\"\"\n",
    "        env = self.env\n",
    "        episode_count = 0\n",
    "        actions = np.empty((batch_size,), dtype=np.int)\n",
    "        dones = np.empty((batch_size,), dtype=np.bool)\n",
    "        rewards, values = np.empty((2, batch_size), dtype=np.float)\n",
    "        observations = np.empty((batch_size,) + self.env.observation_space.shape, dtype=np.float)\n",
    "        obs = self.env.reset()\n",
    "        rewards_test = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Lets collect one batch\n",
    "            for i in range(batch_size):\n",
    "                observations[i] = obs  # just observed s_t\n",
    "                obs_t = torch.from_numpy(obs).float()  # tensor\n",
    "                action = self.actor_network.select_action(obs_t)  # act on just observed, action a_t\n",
    "                actions[i] = int(action)\n",
    "                values[i] = self.value_network(obs_t)  # vhat[t]\n",
    "                \n",
    "                ## Run a step\n",
    "                obs, reward, done, _ = self.env.step(int(action))  # step with env: get (s[t+1], r[t])\n",
    "                \n",
    "                # Store status & reward\n",
    "                dones[i]   = done\n",
    "                rewards[i] = reward\n",
    "                \n",
    "                # check if the observation we just got was terminal\n",
    "                if dones[i]:\n",
    "                    obs = env.reset()\n",
    "\n",
    "            # If our episode didn't end on the last step we need to compute the value for the last state\n",
    "            if dones[-1]:\n",
    "                next_value = 0  # no value function adjustment\n",
    "            else:\n",
    "                obs_t = torch.from_numpy(observations[-1]).float()\n",
    "                next_value = self.value_network.predict(obs_t)\n",
    "            \n",
    "            # Update episode_count\n",
    "            episode_count += sum(dones)\n",
    "\n",
    "            # Compute returns and advantages\n",
    "            returns, advantages = self._returns_advantages(rewards, dones, values, next_value)\n",
    "\n",
    "            # Learning step !\n",
    "            self.optimize_model(observations, actions, returns, dones, advantages)\n",
    "            \n",
    "            \n",
    "            # Test it every 50 epochs\n",
    "            if epoch == 10 or (epoch > 0 and epoch % 25 == 0) or epoch == epochs - 1:\n",
    "                rewards_test.append(np.array([self.evaluate() for _ in range(50)]))\n",
    "                print(f'Epoch {epoch}/{epochs}: Mean rewards: {round(rewards_test[-1].mean(), 2)}, Std: {round(rewards_test[-1].std(), 2)}')\n",
    "\n",
    "                # Early stopping\n",
    "                if rewards_test[-1].mean() > 490 and epoch != epochs -1:\n",
    "                    print('Early stopping !')\n",
    "                    break\n",
    "            \n",
    "            obs = self.env.reset()\n",
    "        \n",
    "        env.close()\n",
    "        \n",
    "        # Plotting\n",
    "        r = pd.DataFrame((itertools.chain(*(itertools.product([i], rewards_test[i]) for i in range(len(rewards_test))))), columns=['Epoch', 'Reward'])\n",
    "        sns.lineplot(x=\"Epoch\", y=\"Reward\", data=r, ci='sd');\n",
    "        \n",
    "        print(f'The training was done over a total of {episode_count} episodes')\n",
    "\n",
    "    def optimize_model(self, observations, actions, returns, dones, advantages):\n",
    "        n_trajs = np.sum(dones)\n",
    "        actions_idx = actions\n",
    "        actions      = F.one_hot(torch.from_numpy(actions), self.env.action_space.n)\n",
    "        returns      = torch.from_numpy(returns[:, None]).float()\n",
    "        advantages   = torch.from_numpy(advantages).float()\n",
    "        observations = torch.from_numpy(observations).float()  # shape (batch_size,)\n",
    "        \n",
    "        # Critic loss\n",
    "        net_values: torch.Tensor = self.value_network(observations)\n",
    "        #critic_loss = F.mse_loss(net_values, returns)\n",
    "        \n",
    "        critic_loss = -torch.mean(advantages * net_values)  # completely equivalent using pseudo-loss\n",
    "        critic_loss.backward()\n",
    "        \n",
    "        self.value_network_optimizer.step()\n",
    "        \n",
    "        # Actor & Entropy loss\n",
    "        \n",
    "        prob: torch.Tensor = self.actor_network(observations)  # shape (batch_size,action_space)\n",
    "        \n",
    "        if not dones[-1]:\n",
    "            n_trajs += 1\n",
    "        \n",
    "        loss = 0.\n",
    "        \n",
    "        for i in range(len(observations)):\n",
    "            loss += torch.log(prob[i, actions_idx[i]])*advantages[i]\n",
    "        \n",
    "        loss = -loss\n",
    "        entropy_term = self.entropy * torch.sum(prob * torch.log(prob))\n",
    "        loss += entropy_term\n",
    "        loss = loss / n_trajs\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.actor_network_optimizer.step()\n",
    "        \n",
    "        self.value_network_optimizer.zero_grad()\n",
    "        self.actor_network_optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        return loss.detach().numpy()\n",
    "\n",
    "    def evaluate(self, render=False):\n",
    "        env = self.monitor_env if render else self.env\n",
    "        observation = env.reset()\n",
    "        observation = torch.from_numpy(observation).float()\n",
    "        reward_episode = 0\n",
    "        done = False\n",
    "        with torch.no_grad():\n",
    "            while not done:\n",
    "                policy = self.actor_network(observation)\n",
    "                action = torch.multinomial(policy, 1)  # draw an action\n",
    "                observation, reward, done, info = env.step(int(action))\n",
    "                observation = torch.from_numpy(observation).float()\n",
    "                reward_episode += reward\n",
    "            \n",
    "        env.close()\n",
    "        if render:\n",
    "            show_video(\"./gym-results\")\n",
    "            print(f'Reward: {reward_episode}')\n",
    "        return reward_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sEwrInsjkDH"
   },
   "source": [
    "Create configuration for A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwDDx78wjmG5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config_a2c is:\n",
      "{'actor_network': {'learning_rate': 0.001},\n",
      " 'entropy': 0.0011,\n",
      " 'env_id': 'CartPole-v1',\n",
      " 'gamma': 0.99,\n",
      " 'seed': 1,\n",
      " 'value_network': {'learning_rate': 0.001}}\n"
     ]
    }
   ],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "value_learning_rate = 0.0010\n",
    "actor_learning_rate = 0.0010\n",
    "gamma = 0.99\n",
    "entropy = 0.0011\n",
    "seed = 1\n",
    "\n",
    "config_a2c = {\n",
    "    'env_id': env_id,\n",
    "    'gamma': gamma,\n",
    "    'seed': seed,\n",
    "    'value_network': {'learning_rate': value_learning_rate},\n",
    "    'actor_network': {'learning_rate': actor_learning_rate},\n",
    "    'entropy': entropy\n",
    "}\n",
    "\n",
    "print(\"Current config_a2c is:\")\n",
    "pprint(config_a2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xW7fe-8jvzY"
   },
   "source": [
    "Run the learning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrZRJ7-yjryp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000: Mean rewards: 27.28, Std: 18.17\n",
      "Epoch 25/1000: Mean rewards: 30.44, Std: 18.89\n",
      "Epoch 50/1000: Mean rewards: 45.02, Std: 25.55\n",
      "Epoch 75/1000: Mean rewards: 55.42, Std: 27.94\n",
      "Epoch 100/1000: Mean rewards: 77.98, Std: 42.76\n",
      "Epoch 125/1000: Mean rewards: 127.84, Std: 77.57\n",
      "Epoch 150/1000: Mean rewards: 188.68, Std: 84.68\n",
      "Epoch 175/1000: Mean rewards: 223.4, Std: 97.46\n",
      "Epoch 200/1000: Mean rewards: 199.96, Std: 89.63\n",
      "Epoch 225/1000: Mean rewards: 239.8, Std: 87.22\n",
      "Epoch 250/1000: Mean rewards: 264.48, Std: 96.99\n",
      "Epoch 275/1000: Mean rewards: 258.1, Std: 97.79\n",
      "Epoch 300/1000: Mean rewards: 344.64, Std: 121.69\n",
      "Epoch 325/1000: Mean rewards: 336.16, Std: 133.71\n",
      "Epoch 350/1000: Mean rewards: 326.84, Std: 105.38\n",
      "Epoch 375/1000: Mean rewards: 346.12, Std: 103.17\n",
      "Epoch 400/1000: Mean rewards: 377.74, Std: 101.34\n",
      "Epoch 425/1000: Mean rewards: 368.32, Std: 115.3\n",
      "Epoch 450/1000: Mean rewards: 408.62, Std: 99.92\n",
      "Epoch 475/1000: Mean rewards: 396.98, Std: 100.09\n",
      "Epoch 500/1000: Mean rewards: 390.8, Std: 116.36\n",
      "Epoch 525/1000: Mean rewards: 476.94, Std: 62.21\n",
      "Epoch 550/1000: Mean rewards: 434.06, Std: 91.15\n",
      "Epoch 575/1000: Mean rewards: 449.32, Std: 87.85\n",
      "Epoch 600/1000: Mean rewards: 456.5, Std: 70.43\n",
      "Epoch 625/1000: Mean rewards: 409.82, Std: 87.34\n",
      "Epoch 650/1000: Mean rewards: 461.02, Std: 79.6\n",
      "Epoch 675/1000: Mean rewards: 464.68, Std: 82.91\n",
      "Epoch 700/1000: Mean rewards: 461.48, Std: 68.2\n",
      "Epoch 725/1000: Mean rewards: 463.22, Std: 76.11\n",
      "Epoch 750/1000: Mean rewards: 451.8, Std: 71.82\n",
      "Epoch 775/1000: Mean rewards: 483.62, Std: 38.45\n",
      "Epoch 800/1000: Mean rewards: 491.14, Std: 51.06\n",
      "Early stopping !\n",
      "The training was done over a total of 1468 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = A2CAgent(config_a2c)\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 384\n",
    "rewards = agent.training_batch(EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzuNtPqTju64"
   },
   "source": [
    "Evaluate the agent over multiple episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bw279M4Jj1y-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MVARL19_part2.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
